[data]
filename=wmt14-manual-evaluation/wmt14-judgments-anonymized.csv
path=/home/elav01/taraxu_data/humaneval/wmt14
pattern_submissions=%(path)s/wmt14-data/plain/system-outputs/newstest2014/%(langpair)s/%(system)s
pattern_sourceref=%(path)s/wmt14-data/plain/sources/newstest2014-%(lang2en)s-src.%(srclang)s
pattern_ref=%(path)s/wmt14-data/plain/references/newstest2014-%(lang2en)s-ref.%(srclang)s

[testsets]

[attributes]
id=srcIndex
document_id=documentId
segment_id=segmentId
judge_id=judgeId
langsrc=srclang
langtgt=trglang

[format]
fieldnames=srclang,trglang,srcIndex,documentId,segmentId,judgeId,system1Number,system1Id,system2Number,system2Id,system3Number,system3Id,system4Number,system4Id,system5Number,system5Id,system1rank,system2rank,system3rank,system4rank,system5rank
systems_num=5
system_indexing_base=1
sentence_indexing_base=1
split_task_column=false
dialect=excel

[filters_include]
srclang=de
trglang=en

[filters_exclude]


[sort]
id=int

[preprocessing]
tokenizer=/home/elav01/taraxu_tools/moses-scripts/tokenizer.perl
tokenize_source=true
tokenize_target=true

[output]
filename=/home/elav01/taraxu_data/jcml/de-en/wmt2014.newstest.de-en.rank.jcml




